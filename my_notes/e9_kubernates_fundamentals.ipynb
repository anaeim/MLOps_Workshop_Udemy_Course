{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AKS Concepts and Their Relationships\n",
    "\n",
    "Let's break down each of these concepts in **Azure Kubernetes Service (AKS)** and explain how they relate to each other in the Kubernetes ecosystem.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Node\n",
    "A **node** is a physical or virtual machine that runs your Kubernetes workloads. In AKS:\n",
    "- Azure manages the control plane.\n",
    "- You manage **worker nodes** (the nodes that run your app containers).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Worker Node\n",
    "This is essentially the **same as a node** in the AKS context ‚Äî it's the VM where **pods** are deployed and run.\n",
    "- Each worker node runs critical Kubernetes components: kubelet, container runtime (e.g., containerd), kube-proxy, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Pods\n",
    "A **pod** is the smallest deployable unit in Kubernetes. It:\n",
    "- Contains one or more containers (usually 1).\n",
    "- Shares storage/network resources.\n",
    "- Is scheduled **on a node**.\n",
    "\n",
    "**Relation**: Pods run **on worker nodes**. The scheduler places pods on nodes that have available resources.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Load Balancer\n",
    "A **load balancer**:\n",
    "- Distributes incoming traffic to the appropriate pod(s).\n",
    "- In AKS, Azure provides a **Layer 4 (TCP/UDP) Load Balancer**.\n",
    "- Useful when exposing your services to the internet (via a `Service` of type `LoadBalancer`).\n",
    "\n",
    "**Relation**: Load balancer routes traffic to **pods** that live on **worker nodes**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Auto Scaling\n",
    "Auto scaling can refer to two types in AKS:\n",
    "1. **Cluster Autoscaler** ‚Äì Scales the number of **nodes** up/down based on resource demand.\n",
    "2. **Horizontal Pod Autoscaler (HPA)** ‚Äì Scales the number of **pod replicas** based on CPU/memory or custom metrics.\n",
    "\n",
    "**Relation**:\n",
    "- If demand increases, HPA adds more **pods**.\n",
    "- If there‚Äôs no space for new pods, the **Cluster Autoscaler** adds **nodes**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Replica\n",
    "A **replica** is a running copy of a pod. Defined in a **Deployment**, it ensures a specified number of pod copies are always running.\n",
    "- Ensures high availability.\n",
    "- If one pod dies, another is created automatically.\n",
    "\n",
    "**Relation**:\n",
    "- Replicas are just multiple instances of pods running on different **nodes**.\n",
    "- Managed using `replicaCount` in YAML or by the HPA.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ scoringTimeoutMs\n",
    "> ‚ö†Ô∏è Not a core Kubernetes term, but commonly used in **ML scenarios** on AKS.\n",
    "\n",
    "- The **maximum time (in milliseconds)** a scoring (inference/prediction) request is allowed to run.\n",
    "- If the time exceeds this, the request fails with a timeout.\n",
    "\n",
    "**Relation**:\n",
    "- Often used in **inference services deployed to AKS**.\n",
    "- Impacts the **pod** handling the scoring request.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ maxQueueWaitMs\n",
    "> ‚ö†Ô∏è Also not a native Kubernetes term; used in ML inference services on AKS.\n",
    "\n",
    "- Defines the **maximum time a request can wait in queue** before being picked up for processing.\n",
    "- If exceeded, the request is dropped or failed.\n",
    "\n",
    "**Relation**:\n",
    "- Queuing happens **before** the request reaches the pod (like in a request router or API gateway).\n",
    "- Helps manage **load** on pods, especially under high traffic.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Relationships Overview\n",
    "\n",
    "| Concept             | Connected To...                              | Description                                 |\n",
    "|---------------------|----------------------------------------------|---------------------------------------------|\n",
    "| **Node / Worker Node** | Pods, Cluster Autoscaler                  | Runs the workload (pods).                   |\n",
    "| **Pod**               | Nodes, Load Balancer, Replicas, Scalers   | Runs containers. Managed via deployments.   |\n",
    "| **Load Balancer**     | Services, Pods                             | Routes external/internal traffic to pods.   |\n",
    "| **Auto Scaling**      | Pods (HPA), Nodes (Cluster Autoscaler)    | Automatically adjusts resource allocation.  |\n",
    "| **Replica**           | Pods, Nodes                                | Keeps desired number of pod instances.      |\n",
    "| **scoringTimeoutMs**  | Pods (especially in ML workloads)         | Defines inference timeout for a request.    |\n",
    "| **maxQueueWaitMs**    | Request queue (before pod handles request)| Sets how long a request can wait in queue.  |\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç What is `kubelet`?\n",
    "\n",
    "The **kubelet** is an essential **agent** that runs on every **node** (including all **worker nodes**) in a Kubernetes cluster.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Responsibilities of Kubelet\n",
    "\n",
    "- Watches for **PodSpecs** (pod definitions) sent by the **Kubernetes control plane**.\n",
    "- Ensures that the containers described in those PodSpecs are **running and healthy**.\n",
    "- Communicates with the **container runtime** (like containerd or Docker).\n",
    "- Reports node and pod status **back to the control plane**.\n",
    "\n",
    "> üí° Think of the kubelet as the \"node supervisor\" that takes orders from the control plane and manages pods locally.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÅ Relation with **Pod**\n",
    "\n",
    "| Component     | Role                                                                 |\n",
    "|---------------|----------------------------------------------------------------------|\n",
    "| **Pod**       | The unit of execution; runs containers.                              |\n",
    "| **kubelet**   | The agent responsible for starting, monitoring, and reporting the pod‚Äôs status on the node. |\n",
    "\n",
    "##### üîß How they interact:\n",
    "\n",
    "- When the Kubernetes **scheduler assigns a pod** to a node:\n",
    "  - The kubelet on that node **receives the PodSpec**.\n",
    "  - It uses the **container runtime** to pull container images and start containers.\n",
    "  - It **monitors the pod‚Äôs lifecycle** and keeps the pod in the desired state.\n",
    "  - It **updates pod status** (Running, Failed, etc.) to the control plane (via the API server).\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÑ Summary\n",
    "\n",
    "- **Pods** are created and run on a node.\n",
    "- **kubelet** ensures those pods stay running and conform to their specs.\n",
    "- kubelet is the **bridge** between the Kubernetes control plane and the containers running on each node.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q. üß† How AKS Determines the Number of Pods on Each Worker Node?\n",
    "\n",
    "Kubernetes (including AKS) uses the **scheduler** to decide **where** to place a pod. The process is generally the same in AKS as in any standard Kubernetes setup.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Scheduler Checks for Available Nodes\n",
    "\n",
    "When a new pod is created:\n",
    "- The **Kubernetes scheduler** looks for **nodes that have enough available resources** (CPU, memory) to run the pod.\n",
    "- It also checks:\n",
    "  - Taints and tolerations\n",
    "  - Node affinity rules\n",
    "  - Resource limits and requests\n",
    "  - Pod topology spread constraints\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Pod Resource Requests and Limits\n",
    "\n",
    "In the pod spec (YAML), you can define:\n",
    "\n",
    "```yaml\n",
    "resources:\n",
    "  requests:\n",
    "    cpu: \"500m\"\n",
    "    memory: \"256Mi\"\n",
    "  limits:\n",
    "    cpu: \"1\"\n",
    "    memory: \"512Mi\"\n",
    "```\n",
    "\n",
    "- `requests`: the minimum CPU/memory the pod needs.\n",
    "- `limits`: the maximum the pod can use.\n",
    "\n",
    "The scheduler uses requests (not limits) to calculate how many pods can fit on a node."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
